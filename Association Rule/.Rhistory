num <- 100
num2 <- 20
num1 <- 100
num2 <- 20
result <- num1 * num2
result
result <- num1 //num2
result <- num1%num2
result <- num1 / num2
result1 <- num1 / num2
result1
result <- num1%%num2
result2 <- num1%%num2
result2
#논리연산자
logical <- num1 >= 50  & num2 <= 10
logical
#조건문
x <- 50; y <- 4; z <- x*y
load("~/Google 드라이브/대학교/2021년 1학기(3학년2학기)/다변량분석/6차 과제/Q7.RData")
best_val_BA
#Bagging 전체 평균 내주기
BA_average <- as.matrix(0,4,1)
BA_average
#Bagging 전체 평균 내주기
BA_average <- matrix(0,4,1)
BA_average
#Bagging 전체 평균 내주기
BA_average <- matrix(0,1,4)
BA_average
colnames(BA_average) <-c("mean_ACC","std_ACC","mean_BCR","std_BCR")
BA_average[1,]
BA_average[1,1] <- mean(best_val_BA[,1])
BA_average
BA_average[1,1] <- mean(best_val_BA[,2])
BA_average
BA_average[1,2] <- mean(best_val_Ba[,3])
BA_average[1,2] <- mean(best_val_BA[,3])
BA_average
BA_average[1,3] <- mean(best_val_BA[,4])
BA_average[1,4] <- mean(best_val_BA[,5])
BA_average
t(perf_eval_multi(best_GBM_cfm))
#----------Q9 데이터 불균형 해소
install.packages("DMwR")
library(DMwR)
#----------Q9 데이터 불균형 해소
install.packages("DMwR")
library(DMwR)
#----------Q9 데이터 불균형 해소
library(caret)
library(ggplot2)
#----------Q9 데이터 불균형 해소
library(DMwR)
#----------Q9 데이터 불균형 해소
install.packages("DMwR")
#----------Q9 데이터 불균형 해소
install.packages("https://cran.r-project.org/src/contrib/Archive/[DMwR].tar.gz", repos = NULL, type="source")
#----------Q9 데이터 불균형 해소
install.packages("DMwR")
#----------Q9 데이터 불균형 해소
library(caret)
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
table(up_data$earthq_target)
up_data
up_data_trn <- up_data[trn_idx,]
up_data_trn <- up_data[trn_idx,]
up_data_tst <- up_data[tst_idx,]
up_data_tst <- up_data[tst_idx,]
up_GBM <- gbm.fit(up_data_trn[,input_idx], up_data_trn[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
#---------------Q7 Gradient Boosting Machine
install.packages("gbm")
library(gbm)
up_GBM <- gbm.fit(up_data_trn[,input_idx], up_data_trn[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
best_criterion
#최적 파라미터 ntree=1000, bag_frac=0.7, shrinkage=0.06
best_bag_frac <- best_GBM_perf[1,2]
best_ntree <- best_GBM_perf[1,1]
best_shrink <- best_GBM_perf[1,3]
#----------Q9 데이터 불균형 해소
library(caret)
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
up_data_trn <- up_data[trn_idx,]
up_data_tst <- up_data[tst_idx,]
up_GBM <- gbm.fit(up_data_trn[,input_idx], up_data_trn[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
table(up_data)
table(up_data$earthq_target)
up_data$earthq_target
View(up_data_tst)
up_data$class
table[up_data$class]
View(earthq_data_scaled)
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
table[up_data$class]
table(up_data$class)
View(up_data)
table(up_data$Class)
up_data_trn <- up_data[trn_idx,]
up_data_tst <- up_data[tst_idx,]
up_data_tst <- up_data[tst_idx,]
up_GBM <- gbm.fit(up_data_trn[,input_idx], up_data_trn[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
up_GBM_prey <-predict(up_GBM, newdata=up_data_tst, type="class")
up_data <- upSample(subset(earthq_data_scaled, select = -Class),earthq_data_scaled$Class)
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
table(up_data$Class)
GBM_trn_data <- data.frame(up_data_trn[,input_idx],DamageYN=up_data_trn[,target_idx])
GBM_tst_data <- data.frame(up_data_tst[,input_idx],DamageYN=up_data_tst[,target_idx])
up_GBM <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
#------[Q7-2]최적 파라미터로 GBM 실행
best_GBM_model <- gbm.fit(GBM_trn[,input_idx],GBM_trn[,target_idx], distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
GBM_trn_data[,input_idx]
#----------Q9 데이터 불균형 해소
library(caret)
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
table(up_data$Class)
up_data_trn <- up_data[trn_idx,]
up_data_tst <- up_data[tst_idx,]
GBM_trn_data <- data.frame(up_data_trn[,input_idx],DamageYN=up_data_trn[,target_idx])
GBM_tst_data <- data.frame(up_data_tst[,input_idx],DamageYN=up_data_tst[,target_idx])
GBM_trn_data[,input_idx]
up_GBM <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
trn <- up_data[sample(nrow(up_data),15000),]
tst <- up_data[sample(nrow(up_tst),6060),]
tst <- up_data[sample(nrow(up_data),6060),]
trn_up <- up_data[sample(nrow(up_data),15000),]
tst_up <- up_data[sample(nrow(up_data),6060),]
trn <- up_data[sample(nrow(up_data),15000),]
tst <- up_data[sample(nrow(up_data),6060),]
GBM_trn_data <- data.frame(trn[,input_idx],DamageYN = trn[,target_idx])
GBM_tst_data <- data.frame(tst[,input_idx],DamageYN = tst[,target_idx])
up_GBM <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
up_GBM_prey <-predict(up_GBM, newdata=GBM_tst_data, type="class")
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst[,input_idx], type="response")
up_GBM_cfm <- table(up_data_tst$Class,up_GBM_prey)
up_GBM_cfm <- table(GBM_tst_data$DamageYN,up_GBM_prey)
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst[,input_idx], type="response")
up_GBM_cfm <- table(GBM_tst_data$DamageYN,up_GBM_prey)
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst[,input_idx], type="response"))
up_GBM_cfm <- table(GBM_tst_data$DamageYN,up_GBM_prey)
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst[,input_idx], type="response"))
up_GBM_cfm <- table(GBM_tst_data$DamageYN,up_GBM_prey)
up_GBM_prey
up_GBM_cfm <- table(max.col(up_GBM_prey),GBM_tst_data$DamageYN)
up_GBM_prey
up_GBM_cfm
t(perf_eval_multi(up_GBM_cfm))
up_data <- upSample(subset(earthq_data_scaled, select = -earthq_target),earthq_data_scaled$earthq_target)
table(up_data$Class)
trn <- up_data[sample(nrow(up_data),15000),]
tst <- up_data[sample(nrow(up_data),6060),]
GBM_trn_data <- data.frame(trn[,input_idx],DamageYN = trn[,target_idx])
GBM_tst_data <- data.frame(tst[,input_idx],DamageYN = tst[,target_idx])
up_GBM <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx],distribution = "multinomial",verbose = TRUE, n.trees = best_ntree, shrinkage = best_shrink, bag.fraction=best_bag_frac)
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst[,input_idx], type="response"))
up_GBM_cfm <- table(max.col(up_GBM_prey),GBM_tst_data$DamageYN)
up_GBM_cfm
t(perf_eval_multi(up_GBM_cfm))
table(earthq_data_scaled$earthq_target)
table(up_data$Class)
val_perf_GBM_up <- matrix(0,27,5)
colnames(val_perf_GBM_up) <- c("ntree","bag_frac","shrinkage","ACC","BCR")
val <- up_data[sample(nrow(up_data),5000),]
GBM_val_data <- data.frame(val[,input_idx],DamageYN = val[,target_idx])
#최적의 파라미터 찾아주기
bag_frac <- c(0.7,0.8,0.9)
ntree <- c(600,800,1000)
shrink <- c(0.02,0.04,0.06)
val <- up_data[sample(nrow(up_data),5000),]
GBM_val_data <- data.frame(val[,input_idx],DamageYN = val[,target_idx])
val_perf_GBM_up <- matrix(0,27,5)
colnames(val_perf_GBM_up) <- c("ntree","bag_frac","shrinkage","ACC","BCR")
iter <-1
for( i in 1:length(ntree)){
cat("GBM: the number of iter:",ntree[i],"\n")
for(j in 1:length(bag_frac)){
cat("bag_frac:",bag_frac[j],"\n")
for(k in 1:length(shrink)){
cat("shrink:",shrink[k],"\n")
eval_fold <- c()
#Training model
GBM_model <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx], distribution = "multinomial",verbose = TRUE, n.trees =ntree[i], shrinkage = shrink[k],bag.fraction=bag_frac[j])
ans <- GBM_val_data$DamageYN
prey <- as.data.frame(predict(GBM_model,GBM_val_data[,input_idx],type="response"))
prey <- max.col(prey)
eval_fold <- rbind(eval_fold,cbind(ans,prey))
#Confusion matrix
cfm <- matrix(0,nrow = 3, ncol = 3)
cfm[1,1] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 1))
cfm[1,2] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 2))
cfm[1,3] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 3))
cfm[2,1] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 1))
cfm[2,2] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 2))
cfm[2,3] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 3))
cfm[3,1] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 1))
cfm[3,2] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 2))
cfm[3,3] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 3))
val_perf_GBM[iter,1] <- ntree[i]
val_perf_GBM[iter,2] <- bag_frac[j]
val_perf_GBM[iter,3] <- shrink[k]
val_perf_GBM[iter,4:5] <- t(perf_eval_multi(cfm))
iter <- iter +1
}
}
}
GBM_val_data <- data.frame(val[,input_idx],DamageYN = val[,target_idx])
val_perf_GBM_up <- matrix(0,27,5)
colnames(val_perf_GBM_up) <- c("ntree","bag_frac","shrinkage","ACC","BCR")
iter <-1
for( i in 1:length(ntree)){
cat("GBM: the number of iter:",ntree[i],"\n")
for(j in 1:length(bag_frac)){
cat("bag_frac:",bag_frac[j],"\n")
for(k in 1:length(shrink)){
cat("shrink:",shrink[k],"\n")
eval_fold <- c()
#Training model
GBM_model <- gbm.fit(GBM_trn_data[,input_idx], GBM_trn_data[,target_idx], distribution = "multinomial",verbose = TRUE, n.trees =ntree[i], shrinkage = shrink[k],bag.fraction=bag_frac[j])
ans <- GBM_val_data$DamageYN
prey <- as.data.frame(predict(GBM_model,GBM_val_data[,input_idx],type="response"))
prey <- max.col(prey)
eval_fold <- rbind(eval_fold,cbind(ans,prey))
#Confusion matrix
cfm <- matrix(0,nrow = 3, ncol = 3)
cfm[1,1] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 1))
cfm[1,2] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 2))
cfm[1,3] <- length(which(eval_fold[,1] == 1 & eval_fold[,2] == 3))
cfm[2,1] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 1))
cfm[2,2] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 2))
cfm[2,3] <- length(which(eval_fold[,1] == 2 & eval_fold[,2] == 3))
cfm[3,1] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 1))
cfm[3,2] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 2))
cfm[3,3] <- length(which(eval_fold[,1] == 3 & eval_fold[,2] == 3))
val_perf_GBM_up[iter,1] <- ntree[i]
val_perf_GBM_up[iter,2] <- bag_frac[j]
val_perf_GBM_up[iter,3] <- shrink[k]
val_perf_GBM_up[iter,4:5] <- t(perf_eval_multi(cfm))
iter <- iter +1
}
}
}
up_GBM_prey <-as.data.frame(predict(up_GBM, GBM_tst_data[,input_idx], type="response"))
up_GBM_cfm <- table(max.col(up_GBM_prey),GBM_tst_data$DamageYN)
up_GBM_cfm
t(perf_eval_multi(up_GBM_cfm))
save.image("~/Google 드라이브/대학교/2021년 1학기(3학년2학기)/다변량분석/6차 과제/A6-Final.RData")
setwd("~/Google 드라이브/대학교/2021년 1학기(3학년2학기)/다변량분석/7차과제")
library(stringr)
library(arules)
library(arulesViz)
library(wordcloud)
load("~/Google 드라이브/대학교/2021년 1학기(3학년2학기)/다변량분석/7차과제/A_7.RData")
rule2 <- subset(rules,lhs%pin%c("MITx_8.02x_UnitedStates_Bachelor's"))
inspect(rule2)
rule2 <- subset(rules,lhs%pin%c("MITx_6.00x_UnitedStates_Bachelor's"))
inspect(rule2)
rule2 <- subset(rules,lhs%pin%c("MITx_8.02x_India_Bachelor's"))
inspect(rule2)
View(rule1)
View(rules1)
View(mooc_dataset)
View(no_rules)
View(rule1)
View(rule2)
#-------[Q3]----- 규칙 생성 및 결과 해석
#-----[Q3-1]
support <- c(0.0005,0.001,0.0015)
confidence <- c(0.05,0.01,0.015)
no_rules <- matrix(0,3,3)
colnames(no_rules) <- paste("Confidence=",confidence)
rownames(no_rules) <- paste("Support=",support)
no_rules
for(i in 1:length(support)){
for(j in 1:length(confidence)){
tmp_rules <- apriori(tmp_big, parameter=list(support=support[i],confidence=confidence[j]))
cnt_rules <- length(tmp_rules)
no_rules[i,j] <- cnt_rules
}
}
no_rules
perf <- rules1$support*rules1$confidence*rules1$lift
rules1 <- cbind(rules1,perf)
sorted_rules <- rules1[order(rules1[,8], decreasing=TRUE),]
sorted_rules
sorted_rules <- rules1[order(rules1[,8], decreasing=TRUE),]
sorted_rules
sorted_rules
plot(rules, method="graph",max=15)
View(sorted_rules)
#규칙 1
rule1 <- subset(rules,lhs%pin%c("MITx_6.002x_United"))
inspect(rule1)
#규칙
rule1 <- subset(rules,lhs%pin%c("MITx_6.002x_United"))
inspect(rule1)
inspect(rule2)
rule2 <- subset(rules,lhs%pin%c("MITx_3.091x_United"))
inspect(rule2)
rule3 <- subset(rules,lhs%pin%c("MITx_6.00x_United>"))
inspect(rule3)
inspect(rule3)
rule3 <- subset(rules,lhs%pin%c("MITx_6.00x_United>"))
inspect(rule3)
a <- 3
a#--------Extra Question
rule3 <- subset(rules,lhs%pin%c("MITx_6.00x_United"))
inspect(rule3)
